<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Chapter 4: Performance Evaluation on Introduction to Machine Learning (I2ML)</title>
    <link>https://compstat-lmu.github.io/lecture_i2ml_2/chapters/04_evaluation/</link>
    <description>Recent content in Chapter 4: Performance Evaluation on Introduction to Machine Learning (I2ML)</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language><atom:link href="https://compstat-lmu.github.io/lecture_i2ml_2/chapters/04_evaluation/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Chapter 4.1: Introduction</title>
      <link>https://compstat-lmu.github.io/lecture_i2ml_2/chapters/04_evaluation/04-01-intro/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://compstat-lmu.github.io/lecture_i2ml_2/chapters/04_evaluation/04-01-intro/</guid>
      <description>&lt;p&gt;It is a crucial part of machine learning to evaluate the performance of a learner. We will explain the concept of generalization error and the difference between inner and outer loss.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Chapter 4.2: Measures Regression</title>
      <link>https://compstat-lmu.github.io/lecture_i2ml_2/chapters/04_evaluation/04-02-measures-regression/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://compstat-lmu.github.io/lecture_i2ml_2/chapters/04_evaluation/04-02-measures-regression/</guid>
      <description>&lt;p&gt;In this section we familiarize ourselves with essential performance measures for regression. In particular, mean squared error (MSE), mean absolute error (MAE), and a straightforward generalization of $R^2$ are discussed.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Chapter 4.3: Measures Classification</title>
      <link>https://compstat-lmu.github.io/lecture_i2ml_2/chapters/04_evaluation/04-03-measures-classification/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://compstat-lmu.github.io/lecture_i2ml_2/chapters/04_evaluation/04-03-measures-classification/</guid>
      <description>&lt;p&gt;Analogous to regression, we consider essential performance measures for classification. As a classifier predicts either class labels or scores/probabilities, its performance can be evaluated based on these two notions. We show some performance measures for classification, including misclassification error rate (MCE), accuracy (ACC) and Brier score (BS). In addition, we will see confusion matrices and learn about costs.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Chapter 4.4: Measures Classification ROC</title>
      <link>https://compstat-lmu.github.io/lecture_i2ml_2/chapters/04_evaluation/04-04-measures-classification-roc/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://compstat-lmu.github.io/lecture_i2ml_2/chapters/04_evaluation/04-04-measures-classification-roc/</guid>
      <description>&lt;p&gt;From the confusion matrix we can calculate a variety of ROC metrics. Among others, we will explain true positive rate, negative predictive value and the $F1$ measure.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Chapter 4.5: Measures Classification ROC Visualization</title>
      <link>https://compstat-lmu.github.io/lecture_i2ml_2/chapters/04_evaluation/04-05-measures-classification-roc-space/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://compstat-lmu.github.io/lecture_i2ml_2/chapters/04_evaluation/04-05-measures-classification-roc-space/</guid>
      <description>&lt;p&gt;In this section, we explain the ROC curve and how to calculate it. In addition, we will present AUC and partial AUC as global performance measures.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Chapter 4.6: Overfitting</title>
      <link>https://compstat-lmu.github.io/lecture_i2ml_2/chapters/04_evaluation/04-06-overfitting/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://compstat-lmu.github.io/lecture_i2ml_2/chapters/04_evaluation/04-06-overfitting/</guid>
      <description>&lt;p&gt;When a machine learning model performs well on training data but does not generalize on the test data, we speak of overfitting. We will show you examples of this behavior and how to diagnose overfitting.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Chapter 4.7: Training Error</title>
      <link>https://compstat-lmu.github.io/lecture_i2ml_2/chapters/04_evaluation/04-07-train/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://compstat-lmu.github.io/lecture_i2ml_2/chapters/04_evaluation/04-07-train/</guid>
      <description>&lt;p&gt;There are two types of errors: training errors and test errors. The focus of this section is on the training error and related difficulties.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Chapter 4.8: Test Error</title>
      <link>https://compstat-lmu.github.io/lecture_i2ml_2/chapters/04_evaluation/04-08-test/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://compstat-lmu.github.io/lecture_i2ml_2/chapters/04_evaluation/04-08-test/</guid>
      <description>&lt;p&gt;While we can infer some information about the learning process from training errors (e.g., the state of iterative optimization), we are truly interested in generalization ability, and thus in the test error on previously unseen data.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Chapter 4.9: Resampling</title>
      <link>https://compstat-lmu.github.io/lecture_i2ml_2/chapters/04_evaluation/04-09-resampling/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://compstat-lmu.github.io/lecture_i2ml_2/chapters/04_evaluation/04-09-resampling/</guid>
      <description>&lt;p&gt;Different resampling techniques help to assess the performance of a learner while avoiding potential quirks resulting from a single train-test split. We will introduce cross-validation (with and without stratification), bootstrap and subsampling.&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>
