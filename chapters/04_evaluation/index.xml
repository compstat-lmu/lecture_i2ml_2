<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Chapter 04: Performance Evaluation on Introduction to Machine Learning (I2ML)</title>
    <link>https://slds-lmu.github.io/i2ml/chapters/04_evaluation/</link>
    <description>Recent content in Chapter 04: Performance Evaluation on Introduction to Machine Learning (I2ML)</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language><atom:link href="https://slds-lmu.github.io/i2ml/chapters/04_evaluation/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Chapter 04.01: Generalization Error</title>
      <link>https://slds-lmu.github.io/i2ml/chapters/04_evaluation/04-01-generalization-error/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://slds-lmu.github.io/i2ml/chapters/04_evaluation/04-01-generalization-error/</guid>
      <description>&lt;p&gt;It is a crucial part of machine learning to evaluate the performance of a learner. We will explain the concept of generalization error and the difference between inner and outer loss.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Chapter 04.02: Measures Regression</title>
      <link>https://slds-lmu.github.io/i2ml/chapters/04_evaluation/04-02-measures-regression/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://slds-lmu.github.io/i2ml/chapters/04_evaluation/04-02-measures-regression/</guid>
      <description>&lt;p&gt;In this section we familiarize ourselves with essential performance measures for regression. In particular, mean squared error (MSE), mean absolute error (MAE), and a straightforward generalization of $R^2$ are discussed.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Chapter 04.03: Training Error</title>
      <link>https://slds-lmu.github.io/i2ml/chapters/04_evaluation/04-03-train/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://slds-lmu.github.io/i2ml/chapters/04_evaluation/04-03-train/</guid>
      <description>&lt;p&gt;There are two types of errors: training errors and test errors. The focus of this section is on the training error and related difficulties.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Chapter 04.04: Test Error</title>
      <link>https://slds-lmu.github.io/i2ml/chapters/04_evaluation/04-04-test/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://slds-lmu.github.io/i2ml/chapters/04_evaluation/04-04-test/</guid>
      <description>&lt;p&gt;While we can infer some information about the learning process from training errors (e.g., the state of iterative optimization), we are truly interested in generalization ability, and thus in the test error on previously unseen data.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Chapter 04.05: Overfitting &amp; Underfitting</title>
      <link>https://slds-lmu.github.io/i2ml/chapters/04_evaluation/04-05-overfitting-underfitting/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://slds-lmu.github.io/i2ml/chapters/04_evaluation/04-05-overfitting-underfitting/</guid>
      <description>&lt;p&gt;In machine learning, we are interested in a model that captures the true underlying function and still generalizes well to new data.
When the model fails on the first task, we speak of underfitting, and both train and test error will be high.
On the other hand, learning the training data very well at the expense of generalization ability is referred to as overfitting and usually occurs when there is not enough data to tell our hypotheses apart.
We will show you examples of this behavior and how to diagnose overfitting.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Chapter 04.06: Resampling 1</title>
      <link>https://slds-lmu.github.io/i2ml/chapters/04_evaluation/04-06-resampling-1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://slds-lmu.github.io/i2ml/chapters/04_evaluation/04-06-resampling-1/</guid>
      <description>&lt;p&gt;Different resampling techniques help to assess the performance of a learner while avoiding potential quirks resulting from a single train-test split. We will introduce cross-validation (with and without stratification), bootstrap and subsampling.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Chapter 04.07: Resampling 2</title>
      <link>https://slds-lmu.github.io/i2ml/chapters/04_evaluation/04-07-resampling-2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://slds-lmu.github.io/i2ml/chapters/04_evaluation/04-07-resampling-2/</guid>
      <description>We provide a deep-dive on resampling, showing its superiority to holdout splitting and analyzing the bias-variance decomposition of its estimator&amp;rsquo;s MSE. We further point out the dependence between CV fold results and that hypothesis testing is therefore not applicable, and give some practical tips to choose resampling strategies.
Lecture video   Lecture slides  Previous &amp;nbsp; Page:  /  &amp;nbsp; Next PDF     window.addEventListener(&#34;load&#34;,function(){ var url = &#39;https:\/\/slds-lmu.</description>
    </item>
    
    <item>
      <title>Chapter 04.08: Measures Classification</title>
      <link>https://slds-lmu.github.io/i2ml/chapters/04_evaluation/04-08-measures-classification/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://slds-lmu.github.io/i2ml/chapters/04_evaluation/04-08-measures-classification/</guid>
      <description>&lt;p&gt;Analogous to regression, we consider essential performance measures for classification. As a classifier predicts either class labels or scores/probabilities, its performance can be evaluated based on these two notions. We show some performance measures for classification, including misclassification error rate (MCE), accuracy (ACC) and Brier score (BS). In addition, we will see confusion matrices and learn about costs.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Chapter 04.09: Measures Classification ROC</title>
      <link>https://slds-lmu.github.io/i2ml/chapters/04_evaluation/04-09-measures-classification-roc/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://slds-lmu.github.io/i2ml/chapters/04_evaluation/04-09-measures-classification-roc/</guid>
      <description>&lt;p&gt;From the confusion matrix we can calculate a variety of ROC metrics. Among others, we will explain true positive rate, negative predictive value and the $F1$ measure.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Chapter 04.10: Measures Classification ROC Visualization</title>
      <link>https://slds-lmu.github.io/i2ml/chapters/04_evaluation/04-10-measures-classification-roc-space/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://slds-lmu.github.io/i2ml/chapters/04_evaluation/04-10-measures-classification-roc-space/</guid>
      <description>&lt;p&gt;In this section, we explain the ROC curve and how to calculate it. In addition, we will present AUC and partial AUC as global performance measures.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Chapter 04.11: AUC Extensions</title>
      <link>https://slds-lmu.github.io/i2ml/chapters/04_evaluation/04-11-auc_extensions/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://slds-lmu.github.io/i2ml/chapters/04_evaluation/04-11-auc_extensions/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Chapter 04.12: Beyond AUC</title>
      <link>https://slds-lmu.github.io/i2ml/chapters/04_evaluation/04-12-beyond_auc/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://slds-lmu.github.io/i2ml/chapters/04_evaluation/04-12-beyond_auc/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
