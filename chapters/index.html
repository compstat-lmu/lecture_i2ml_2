<!DOCTYPE html>
<html><head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-EVSTQN3/azprG1Anm3QDgpJLIm9Nao0Yz1ztcQTwFspd3yD65VohhpuuCOmLASjC" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="/lecture_i2ml_2/css/style.css">


<title>Introduction to Machine Learning (I2ML) | Chapters</title>


<link rel="apple-touch-icon" sizes="180x180" href="/lecture_i2ml_2/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/lecture_i2ml_2/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/lecture_i2ml_2/favicon-16x16.png">
<link rel="manifest" href="/lecture_i2ml_2/site.webmanifest">
<link rel="mask-icon" href="/lecture_i2ml_2/safari-pinned-tab.svg" color="#5bbad5">
<meta name="msapplication-TileColor" content="#da532c">
<meta name="theme-color" content="#ffffff">

</head><body>
<img id="logo" src="/lecture_i2ml_2/i2ml.svg" />

<div id="nav-border" class="container">
    <nav id="nav" class="nav justify-content-center">
        
        <a class="nav-link" href="/lecture_i2ml_2">
        
        Home
        </a>
        
        <a class="nav-link" href="/lecture_i2ml_2/chapters/">
        
        Chapters
        </a>
        
        <a class="nav-link" href="/lecture_i2ml_2/appendix/">
        
        Appendix
        </a>
        
        <a class="nav-link" href="/lecture_i2ml_2/team/">
        
        Team
        </a>
        
    </nav>
</div><div id="content" class="container">
<h1>Chapters</h1>

<p></p>


<div class="chapter_overview">
<ul class="list-unstyled">


<li>
    <a class="title" href="/lecture_i2ml_2/chapters/01_ml_basics/">Chapter 1: ML Basics</a>
    
      
        <p>This chapter introduces the basic concepts of machine learning. We focus on supervised learning, explain the difference between regression and classification, show how to evaluate and compare machine learning models and formalize the concept of learning.</p>
      
      
</li>

<li>
    <a class="title" href="/lecture_i2ml_2/chapters/02_supervised_regression/">Chapter 2: Supervised Regression</a>
    
      
        <p>This chapter treats the supervised regression task in more detail. We will see different loss functions for regression, how a linear regression model can be used from a machine learning perspective, and how to extend it with polynomials for greater flexibility.</p>
      
      
</li>

<li>
    <a class="title" href="/lecture_i2ml_2/chapters/03_supervised_classification/">Chapter 3: Supervised Classification</a>
    
      
        <p>This chapter treats the supervised classification task in more detail. We will see examples of binary and multi-class classification and the differences between discriminative and generative approaches. In particular, we will address logistic regression, linear and quadratic discriminant analysis, and naive Bayes classifiers.</p>
      
      
</li>

<li>
    <a class="title" href="/lecture_i2ml_2/chapters/04_evaluation/">Chapter 4: Performance Evaluation</a>
    
      
        <p>This chapter treats the challenge of evaluating the performance of a model. We will introduce different performance measures for regression and classification tasks, explain the problem of overfitting as well as the difference between training and test error, and finally present a variety of resampling techniques.</p>
      
      
</li>

<li>
    <a class="title" href="/lecture_i2ml_2/chapters/05_knn/">Chapter 5: k-Nearest Neighbors (k-NN)</a>
    
      
        <p>This chapter addresses \(k\)-nearest neighbors, a distance-based algorithm suited to both regression and classification. Predictions are made based upon neighboring observations, assuming feature similarity translates to target similarity.</p>
      
      
</li>

<li>
    <a class="title" href="/lecture_i2ml_2/chapters/06_trees/">Chapter 6: Classification and Regression Trees (CART)</a>
    
      
        <p>This chapter introduces Classification and Regression Trees (CART), a well-established machine learning procedure. We explain the main idea and give details on splitting criteria, discuss computational aspects of growing a tree, and illustrate the idea of stopping criteria and pruning.</p>
      
      
</li>

<li>
    <a class="title" href="/lecture_i2ml_2/chapters/07_forests/">Chapter 7: Random Forests</a>
    
      
        <p>This chapter introduces bagging as method to increase the performance of trees. A modification of bagging leads to random forests. We explain the main idea of random forests, benchmark their performance with the methods seen so far and show how to quantify the impact of a single feature on the performance of the random forest as well as how to compute proximities between observations based on random forests.</p>
      
      
</li>

<li>
    <a class="title" href="/lecture_i2ml_2/chapters/08_tuning/">Chapter 8: Tuning</a>
    
      
        <p>This chapter introduces and formalizes the problem of hyperparameter tuning. We will only cover basic techniques here.</p>
      
      
</li>


</ul>
</div>


        </div><footer class="bg-light text-center text-lg-start fixed-bottom">
<ul class="list-inline text-center">
  <li class="list-inline-item">Â© 2021 Course Creator</li>
  
  <li class="list-inline-item"><a class="nav-link" href="https://github.com/compstat-lmu/lecture_i2ml" target="_blank">Course content</a></li>
  
  <li class="list-inline-item"><a class="nav-link" href="/lecture_i2ml_2" target="_blank">Main Course Website</a></li>
  
  <li class="list-inline-item"><a class="nav-link" href="https://github.com/jakob-r/hugo-course" target="_blank">Website source code</a></li>
  
</ul>
</footer>

<script>
  MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']],
      displayMath: [['$$','$$'], ['\\[', '\\]']],
      processEscapes: true,
      processEnvironments: true
    },
    options: {
      skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
      ignoreHtmlClass: ['quizdown']
    }
  };

  window.addEventListener('load', (event) => {
      document.querySelectorAll("mjx-container").forEach(function(x){
        x.parentElement.classList += 'has-jax'})
    });

</script>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script type="text/javascript" id="MathJax-script" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

</body>
</html>
