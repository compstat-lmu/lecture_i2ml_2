---
title: "Chapter 13.06: Information Theory for Machine Learning"
weight: 130036
---
In this section, we discuss how information-theoretic concepts are used in machine learning and demonstrate the equivalence of KL minimization and maximum likelihood maximization, as well as how (cross-)entropy can be used as a loss function. 

<!--more-->

### Lecture video

{{< video id="GX4HwGpbkFw" >}}

### Lecture slides

{{< pdfjs file="slides-info-ml.pdf" >}}
