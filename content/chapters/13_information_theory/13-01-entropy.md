---
title: "Chapter 13.1: Entropy"
weight: 13010
---
We introduce entropy, which expresses the expected information for discrete random variables, as a central concept in information theory. 

<!--more-->

### Lecture video

{{< video id="9H-DkQN0nxM" >}}

### Lecture slides

{{< pdfjs file="slides-info-entropy.pdf" >}}
