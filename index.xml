<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Introduction to Machine Learning (I2ML) on My New Hugo Course Site</title>
    <link>https://jakob-r.de/hugo-course/</link>
    <description>Recent content in Introduction to Machine Learning (I2ML) on My New Hugo Course Site</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language><atom:link href="https://jakob-r.de/hugo-course/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Chapter 1.1: What is ML?</title>
      <link>https://jakob-r.de/hugo-course/chapters/01_ml_basics/01_01_what_is_ml/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://jakob-r.de/hugo-course/chapters/01_ml_basics/01_01_what_is_ml/</guid>
      <description>As subtopic of artificial intelligence, machine learning is a mathematically well-defined discipline and usually constructs predictive or decision models from data, instead of explicitly programming them. In this section, you will see some typical examples of where machine learning is applied and the main directions of machine learning.
   Previous &amp;nbsp; Page:  /  &amp;nbsp; Next PDF     window.onload = function() { var url = &#39;.</description>
    </item>
    
    <item>
      <title>Chapter 1.2: Data</title>
      <link>https://jakob-r.de/hugo-course/chapters/01_ml_basics/01_02_data/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://jakob-r.de/hugo-course/chapters/01_ml_basics/01_02_data/</guid>
      <description>In this section we explain the basic structure of tabular data used in machine learning. We will differentiate targets from features, talk about labeled and unlabeled data and introduce the concept of the data generating process.
  </description>
    </item>
    
    <item>
      <title>Chapter 1.3: Tasks</title>
      <link>https://jakob-r.de/hugo-course/chapters/01_ml_basics/01_03_tasks/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://jakob-r.de/hugo-course/chapters/01_ml_basics/01_03_tasks/</guid>
      <description>The tasks of supervised learning can roughly be divided in two categories: regression (for continuous outcome) and classification (for categorical outcome). We will present some examples.
   Previous &amp;nbsp; Page:  /  &amp;nbsp; Next PDF     window.onload = function() { var url = &#39;../slides-basics-task.pdf&#39;; var hidePaginator = &#34;&#34;; var pdfjsLib = window[&#39;pdfjs-dist/build/pdf&#39;]; pdfjsLib.GlobalWorkerOptions.workerSrc = &#34;https://cdn.jsdelivr.net/npm/pdfjs-dist@2.9.359/build/pdf.worker.min.js&#34;; var pdfDoc = null, pageNum = 1, pageRendering = false, pageNumPending = null, scale = 3, canvas = document.</description>
    </item>
    
    <item>
      <title>Chapter 2.1: Loss Functions for Regression</title>
      <link>https://jakob-r.de/hugo-course/chapters/02_supervised_regression/02_01_loss_functions_for_regression/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://jakob-r.de/hugo-course/chapters/02_supervised_regression/02_01_loss_functions_for_regression/</guid>
      <description>&lt;p&gt;L1 and L2 are two essential loss functions used for evaluating the performance of regression models. This section defines L1 and L2 loss and explains the differences.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Cheat Sheets</title>
      <link>https://jakob-r.de/hugo-course/appendix/01_cheat_sheets/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://jakob-r.de/hugo-course/appendix/01_cheat_sheets/</guid>
      <description>Download</description>
    </item>
    
    <item>
      <title>Errata</title>
      <link>https://jakob-r.de/hugo-course/appendix/02_errata/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://jakob-r.de/hugo-course/appendix/02_errata/</guid>
      <description>Errata in the slides shown in the videos  Chapter 1.4 (Models &amp;amp; Parameters) - slide 5/10: d-dimensional vector, not p-dimensional Chapter 4.3 (Simple Measures for Classification) - slide 6/9: Error in cost matrix Chapter 5.2 (CART: Splitting Criteria) - slide 12/12: Error in result of Gini Chapter 6.2 (Forests: Intro) - slides 7/8 and 8/8: Error in OOB error Chapter 6.4 (Forests: Feature importance) - slide 3/3: Error in permutation based variable importance  </description>
    </item>
    
    <item>
      <title>Hugo Quiz</title>
      <link>https://jakob-r.de/hugo-course/quiz/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://jakob-r.de/hugo-course/quiz/</guid>
      <description> --- primary_color: orange secondary_color: lightgray text_color: black shuffle_questions: false --- ## The sound of dog --- shuffle_answers: false --- What do dogs sound $1+1$ like?  Some hint - [ ] yes - [ ] no - [ ] `self.sound = &#34;meow&#34;` - [x] wuff ## Put the [days](https://en.wikipedia.org/wiki/Day) in order!  Monday is the *first* day of the week. 1. Monday 2. Tuesday 3. Wednesday 4. Friday 5. Saturday  </description>
    </item>
    
  </channel>
</rss>
