<!DOCTYPE html>
<html><head>
	<meta name="generator" content="Hugo 0.88.1" />
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-EVSTQN3/azprG1Anm3QDgpJLIm9Nao0Yz1ztcQTwFspd3yD65VohhpuuCOmLASjC" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="/lecture_i2ml_2/css/style.css">


<title>Introduction to Machine Learning (I2ML)</title>


<link rel="apple-touch-icon" sizes="180x180" href="/lecture_i2ml_2/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/lecture_i2ml_2/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/lecture_i2ml_2/favicon-16x16.png">
<link rel="manifest" href="/lecture_i2ml_2/site.webmanifest">
<link rel="mask-icon" href="/lecture_i2ml_2/safari-pinned-tab.svg" color="#5bbad5">
<meta name="msapplication-TileColor" content="#da532c">
<meta name="theme-color" content="#ffffff">

</head><body>
<img id="logo" src="/lecture_i2ml_2/i2ml.svg" />

<div id="nav-border" class="container">
    <nav id="nav" class="nav justify-content-center">
        
        <a class="nav-link" href="/lecture_i2ml_2">
        
        Home
        </a>
        
        <a class="nav-link" href="/lecture_i2ml_2/chapters/">
        
        Chapters
        </a>
        
        <a class="nav-link" href="/lecture_i2ml_2/appendix/">
        
        Appendix
        </a>
        
        <a class="nav-link" href="/lecture_i2ml_2/team/">
        
        Team
        </a>
        
    </nav>
</div><div id="content" class="container">
<h1>Introduction to Machine Learning (I2ML)</h1>
<p>This website offers an open and free introductory course on (supervised) machine learning. The course is constructed holistically and as self-contained as possible, in order to cover most relevant areas of supervised ML. While the introductory parts are more aimed at a practical and operational understanding of the covered algorithms and models, we also include sound theoretical foundations and proofs in more advanced sections in order to teach ML theory as self-contained and precise as possible.</p>
<p>It can either be taken as an introductory undergraduate course early on - if you skip the more advanced sections - or as an introductory graduate-level course for Master&rsquo;s level students.</p>
<p>One general, important goal of the course - on top of clearly explaining the most popular ML algorithms - is to clearly demonstrate the fundamental building blocks behind ML, instead of introducing &ldquo;yet another algorithm, with yet another differently named concept&rdquo;. We discuss, compare and contrast risk minimization, statistical parameter estimation, the Bayesian viewpoint and information theory and demonstrate that all of these are equally valid entry points to ML - which often (confusingly) talk about the same thing with different terminology. Being able to understand these similarities and enabling to mentally switch perspectives when needed is a major goal of this course.</p>
<p>If you want to learn more about this course, please (1) read the outline further below and (2) read the section on prerequisites</p>
<p>Later on, please note: (1) The course uses a unified mathematical notation. We provide cheat sheets to summarize the most important symbols and concepts. (2) Most sections already contain quizzes, coding demos, and exercises with worked-out solutions to enable self-study as much as possible.</p>
<p>What this course does not cover - in order to not have its scope grow completely out of hand: (1) Neural networks and deep learning. We are currently working on a similar repo / page for that, which builds upon this course. (2) An in-depth coverage of optimization. We might publish a course on that at some point, but this is currently lower priority.</p>
<p>While most of the course is on a conceptual, programming language-independent level - which is by design - we offer a large variety of applied exercises in R, often using the mlr3 package and its corresponding universe. We are working on offering the exercises in python as well.</p>
<p>Note: In summer semester 2021 we are still extending the material somewhat, so the complete first version including all advanced material will probably be available around 07/2021.</p>
<p>The course material is developed in a public github repository: <a href="https://github.com/compstat-lmu/lecture_i2ml">https://github.com/compstat-lmu/lecture_i2ml</a>. You can find the changelog at: <a href="https://github.com/compstat-lmu/lecture_i2ml/blob/master/CHANGELOG.md">https://github.com/compstat-lmu/lecture_i2ml/blob/master/CHANGELOG.md</a>.</p>
<p>If you love teaching ML and have free resources available, please consider joining the team and email us now! (<a href="mailto:bernd.bischl@stat.uni-muenchen.de">bernd.bischl@stat.uni-muenchen.de</a> or <a href="mailto:ludwig.bothmann@stat.uni-muenchen.de">ludwig.bothmann@stat.uni-muenchen.de</a>)</p>



<hr />




<div class="chapter_overview" id="index_chapters">
<ul class="list-unstyled">


<li><a class="title" href="/lecture_i2ml_2/chapters/01_ml_basics/">Chapter 1: ML Basics</a>

<ul>
  
  <li><a class="title" href="/lecture_i2ml_2/chapters/01_ml_basics/01-01-basics-whatisml/">Chapter 1.1: What is ML?</a></li>
  
  <li><a class="title" href="/lecture_i2ml_2/chapters/01_ml_basics/01-02-data/">Chapter 1.2: Data</a></li>
  
  <li><a class="title" href="/lecture_i2ml_2/chapters/01_ml_basics/01-03-tasks/">Chapter 1.3: Tasks</a></li>
  
  <li><a class="title" href="/lecture_i2ml_2/chapters/01_ml_basics/01-04-models-parameters/">Chapter 1.4: Models and Parameters</a></li>
  
  <li><a class="title" href="/lecture_i2ml_2/chapters/01_ml_basics/01-05-learner/">Chapter 1.5: Learner</a></li>
  
  <li><a class="title" href="/lecture_i2ml_2/chapters/01_ml_basics/01-06-riskminimization/">Chapter 1.6: Losses and Risk Minimization</a></li>
  
  <li><a class="title" href="/lecture_i2ml_2/chapters/01_ml_basics/01-07-optimization/">Chapter 1.7: Optimization</a></li>
  
  <li><a class="title" href="/lecture_i2ml_2/chapters/01_ml_basics/01-08-learnercomponents-hro/">Chapter 1.8: Components of a Learner</a></li>
  
</ul>

</li>

<li><a class="title" href="/lecture_i2ml_2/chapters/02_supervised_regression/">Chapter 2: Supervised Regression</a>

<ul>
  
  <li><a class="title" href="/lecture_i2ml_2/chapters/02_supervised_regression/02-01-losses/">Chapter 2.1: Loss Functions for Regression</a></li>
  
  <li><a class="title" href="/lecture_i2ml_2/chapters/02_supervised_regression/02-02-linearmodel/">Chapter 2.2: Linear Regression Models</a></li>
  
  <li><a class="title" href="/lecture_i2ml_2/chapters/02_supervised_regression/02-03-polynomials/">Chapter 2.3: Polynomial Regression Models</a></li>
  
</ul>

</li>

<li><a class="title" href="/lecture_i2ml_2/chapters/03_supervised_classification/">Chapter 3: Supervised Classification</a>

<ul>
  
  <li><a class="title" href="/lecture_i2ml_2/chapters/03_supervised_classification/03-01-tasks/">Chapter 3.1: Classification Tasks</a></li>
  
  <li><a class="title" href="/lecture_i2ml_2/chapters/03_supervised_classification/03-02-classification-basicdefs/">Chapter 3.2: Basic Definitions</a></li>
  
  <li><a class="title" href="/lecture_i2ml_2/chapters/03_supervised_classification/03-03-classification-linear/">Chapter 3.3: Linear Classifiers</a></li>
  
  <li><a class="title" href="/lecture_i2ml_2/chapters/03_supervised_classification/03-04-classification-logistic/">Chapter 3.4: Logistic Regression</a></li>
  
  <li><a class="title" href="/lecture_i2ml_2/chapters/03_supervised_classification/03-05-classification-discranalysis/">Chapter 3.5: Discriminant Analysis</a></li>
  
  <li><a class="title" href="/lecture_i2ml_2/chapters/03_supervised_classification/03-06-classification-naivebayes/">Chapter Chapter 3.6: Naive Bayes</a></li>
  
</ul>

</li>

<li><a class="title" href="/lecture_i2ml_2/chapters/04_evaluation/">Chapter 4: Performance Evaluation</a>

<ul>
  
  <li><a class="title" href="/lecture_i2ml_2/chapters/04_evaluation/04-01-intro/">Chapter 4.1: Introduction</a></li>
  
  <li><a class="title" href="/lecture_i2ml_2/chapters/04_evaluation/04-02-measures-regression/">Chapter 4.2: Measures Regression</a></li>
  
  <li><a class="title" href="/lecture_i2ml_2/chapters/04_evaluation/04-03-measures-classification/">Chapter 4.3: Measures Classification</a></li>
  
  <li><a class="title" href="/lecture_i2ml_2/chapters/04_evaluation/04-04-measures-classification-roc/">Chapter 4.4: Measures Classification ROC</a></li>
  
  <li><a class="title" href="/lecture_i2ml_2/chapters/04_evaluation/04-05-measures-classification-roc-space/">Chapter 4.5: Measures Classification ROC Visualization</a></li>
  
  <li><a class="title" href="/lecture_i2ml_2/chapters/04_evaluation/04-06-overfitting/">Chapter 4.6: Overfitting</a></li>
  
  <li><a class="title" href="/lecture_i2ml_2/chapters/04_evaluation/04-07-train/">Chapter 4.7: Training Error</a></li>
  
  <li><a class="title" href="/lecture_i2ml_2/chapters/04_evaluation/04-08-test/">Chapter 4.8: Test Error</a></li>
  
  <li><a class="title" href="/lecture_i2ml_2/chapters/04_evaluation/04-09-resampling/">Chapter 4.9: Resampling</a></li>
  
</ul>

</li>

<li><a class="title" href="/lecture_i2ml_2/chapters/05_knn/">Chapter 5: k-Nearest Neighbors (k-NN)</a>

<ul>
  
  <li><a class="title" href="/lecture_i2ml_2/chapters/05_knn/05-01-knn/">Chapter 5.1: k-Nearest Neighbors (k-NN)</a></li>
  
</ul>

</li>

<li><a class="title" href="/lecture_i2ml_2/chapters/06_trees/">Chapter 6: Classification and Regression Trees (CART)</a>

<ul>
  
  <li><a class="title" href="/lecture_i2ml_2/chapters/06_trees/06-01-intro/">Chapter 6.1: Introduction</a></li>
  
  <li><a class="title" href="/lecture_i2ml_2/chapters/06_trees/06-02-splitcriteria/">Chapter 6.2: Splitting Criteria</a></li>
  
  <li><a class="title" href="/lecture_i2ml_2/chapters/06_trees/06-03-treegrowing/">Chapter 6.3: Growing a Tree</a></li>
  
  <li><a class="title" href="/lecture_i2ml_2/chapters/06_trees/06-04-splitcomputation/">Chapter 6.4: Computational Aspects of Finding Splits</a></li>
  
  <li><a class="title" href="/lecture_i2ml_2/chapters/06_trees/06-05-stoppingpruning/">Chapter 6.5: Stopping Criteria &amp; Pruning</a></li>
  
  <li><a class="title" href="/lecture_i2ml_2/chapters/06_trees/06-06-discussion/">Chapter 6.6: Discussion</a></li>
  
</ul>

</li>

<li><a class="title" href="/lecture_i2ml_2/chapters/07_forests/">Chapter 7: Random Forests</a>

<ul>
  
  <li><a class="title" href="/lecture_i2ml_2/chapters/07_forests/07-01-bagging/">Chapter 7.1: Bagging Ensembles</a></li>
  
  <li><a class="title" href="/lecture_i2ml_2/chapters/07_forests/07-02-intro/">Chapter 7.2: Introduction</a></li>
  
  <li><a class="title" href="/lecture_i2ml_2/chapters/07_forests/07-03-benchmark/">Chapter 7.3: Benchmarking Trees, Forests, and Bagging K-NN</a></li>
  
  <li><a class="title" href="/lecture_i2ml_2/chapters/07_forests/07-04-featureimportance/">Chapter 7.4: Feature Importance</a></li>
  
  <li><a class="title" href="/lecture_i2ml_2/chapters/07_forests/07-05-proximities/">Chapter 7.5: Proximities</a></li>
  
  <li><a class="title" href="/lecture_i2ml_2/chapters/07_forests/07-06-discussion/">Chapter 7.6: Discussion</a></li>
  
</ul>

</li>

<li><a class="title" href="/lecture_i2ml_2/chapters/08_tuning/">Chapter 8: Tuning</a>

<ul>
  
  <li><a class="title" href="/lecture_i2ml_2/chapters/08_tuning/08-01-intro/">Chapter 8.1: Introduction</a></li>
  
  <li><a class="title" href="/lecture_i2ml_2/chapters/08_tuning/08-02-tuning-tuningproblem/">Chapter 8.2: Problem Definition</a></li>
  
  <li><a class="title" href="/lecture_i2ml_2/chapters/08_tuning/08-03-basicalgos/">Chapter 8.3: Basic Techniques</a></li>
  
</ul>

</li>

<li><a class="title" href="/lecture_i2ml_2/chapters/09_nested_resampling/">Chapter 9: Nested Resampling</a>

<ul>
  
  <li><a class="title" href="/lecture_i2ml_2/chapters/09_nested_resampling/09-01-nestedintro/">Chapter 9.1: Nested Resampling Motivation</a></li>
  
  <li><a class="title" href="/lecture_i2ml_2/chapters/09_nested_resampling/09-02-trainvalidtest/">Chapter 9.2: Training - Validation - Testing</a></li>
  
  <li><a class="title" href="/lecture_i2ml_2/chapters/09_nested_resampling/09-03-nestedresampling/">Chapter 9.3: Nested Resampling</a></li>
  
</ul>

</li>

<li><a class="title" href="/lecture_i2ml_2/chapters/10_mlr3/">Chapter 10: mlr3</a>

<ul>
  
  <li><a class="title" href="/lecture_i2ml_2/chapters/10_mlr3/10-01-intro/">Chapter 10.1: Intro to mlr3</a></li>
  
  <li><a class="title" href="/lecture_i2ml_2/chapters/10_mlr3/10-02-resampling/">Chapter 10.2: Resampling with mlr3</a></li>
  
  <li><a class="title" href="/lecture_i2ml_2/chapters/10_mlr3/10-03-tuning/">Chapter 10.3: Tuning with mlr3</a></li>
  
  <li><a class="title" href="/lecture_i2ml_2/chapters/10_mlr3/10-04-pipelines/">Chapter 10.4: Pipelines with mlr3</a></li>
  
</ul>

</li>

</ul>
</div>





<div class="chapter_overview" id="index_appendix">
<ul class="list-unstyled">


<li><a class="title" href="/lecture_i2ml_2/appendix/01_cheat_sheets/">Cheat Sheets</a></li>

<li><a class="title" href="/lecture_i2ml_2/appendix/02_errata/">Errata</a></li>


</ul>
</div>


        </div><footer class="bg-light text-center text-lg-start fixed-bottom">
<ul class="list-inline text-center">
  <li class="list-inline-item">© 2021 Course Creator</li>
  
  <li class="list-inline-item"><a class="nav-link" href="https://github.com/compstat-lmu/lecture_i2ml" target="_blank">Course content</a></li>
  
  <li class="list-inline-item"><a class="nav-link" href="/lecture_i2ml_2" target="_blank">Main Course Website</a></li>
  
  <li class="list-inline-item"><a class="nav-link" href="https://github.com/jakob-r/hugo-course" target="_blank">Website source code</a></li>
  
</ul>
</footer>

<script>
  MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']],
      displayMath: [['$$','$$'], ['\\[', '\\]']],
      processEscapes: true,
      processEnvironments: true
    },
    options: {
      skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
      ignoreHtmlClass: ['quizdown']
    }
  };

  window.addEventListener('load', (event) => {
      document.querySelectorAll("mjx-container").forEach(function(x){
        x.parentElement.classList += 'has-jax'})
    });

</script>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script type="text/javascript" id="MathJax-script" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

</body>
</html>
